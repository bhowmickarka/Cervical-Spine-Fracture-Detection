{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q ../input/for-pydicom/pylibjpeg-1.4.0-py3-none-any.whl\n!pip install -q ../input/for-pydicom/python_gdcm-3.0.14-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n!pip install -q ../input/for-pydicom/pylibjpeg_libjpeg-1.3.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n!pip install -q -U keras-tuner","metadata":{"execution":{"iopub.status.busy":"2022-09-03T12:12:53.533241Z","iopub.execute_input":"2022-09-03T12:12:53.533961Z","iopub.status.idle":"2022-09-03T12:13:31.282106Z","shell.execute_reply.started":"2022-09-03T12:12:53.533842Z","shell.execute_reply":"2022-09-03T12:13:31.280819Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# Note : #\n\n### In this notebook we are going to use Keras tuner to tune hyperparamteres, like Learning Rate to see improvement in the training process ###","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfrom glob import glob\nimport pydicom\nimport tensorflow as tf\nimport tqdm as tqdm\nimport tensorflow_io as tfio\nimport pathlib\nimport datetime\nfrom tensorflow import keras\nimport keras_tuner as kt","metadata":{"execution":{"iopub.status.busy":"2022-09-03T12:14:57.540639Z","iopub.execute_input":"2022-09-03T12:14:57.541696Z","iopub.status.idle":"2022-09-03T12:15:00.257597Z","shell.execute_reply.started":"2022-09-03T12:14:57.541655Z","shell.execute_reply":"2022-09-03T12:15:00.256531Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"DATA_DIR = \"../input/rsna-2022-cervical-spine-fracture-detection/\"\ntrainCsv = \"../input/rsna-2022-cervical-spine-fracture-detection/train.csv\"\ntrain_df = pd.read_csv(trainCsv)\nprint(train_df.head())","metadata":{"execution":{"iopub.status.busy":"2022-09-03T12:15:05.689922Z","iopub.execute_input":"2022-09-03T12:15:05.690501Z","iopub.status.idle":"2022-09-03T12:15:05.708368Z","shell.execute_reply.started":"2022-09-03T12:15:05.690468Z","shell.execute_reply":"2022-09-03T12:15:05.707488Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"            StudyInstanceUID  patient_overall  C1  C2  C3  C4  C5  C6  C7\n0   1.2.826.0.1.3680043.6200                1   1   1   0   0   0   0   0\n1  1.2.826.0.1.3680043.27262                1   0   1   0   0   0   0   0\n2  1.2.826.0.1.3680043.21561                1   0   1   0   0   0   0   0\n3  1.2.826.0.1.3680043.12351                0   0   0   0   0   0   0   0\n4   1.2.826.0.1.3680043.1363                1   0   0   0   0   1   0   0\n","output_type":"stream"}]},{"cell_type":"code","source":"def load_dicom(path):\n    \"\"\"\n    reads a dicom file and loads the image array inside it\n    inputs:\n        path: the path of the required dicom file\n    returns:\n        data: image pixel arrays\n    \"\"\"\n    img=pydicom.dcmread(path)\n    data=img.pixel_array\n    data=data-np.min(data)\n    if np.max(data) != 0:\n        data=data/np.max(data)\n    data=(data*255).astype(np.uint8)\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-09-03T12:15:10.326763Z","iopub.execute_input":"2022-09-03T12:15:10.327486Z","iopub.status.idle":"2022-09-03T12:15:10.333797Z","shell.execute_reply.started":"2022-09-03T12:15:10.327450Z","shell.execute_reply":"2022-09-03T12:15:10.332795Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def data_generator():\n    for i, study_instance in enumerate(train_df.StudyInstanceUID[:]):\n        for dcm in os.listdir(DATA_DIR + f\"train_images/{study_instance}\"):\n            train_labels = []\n            path = DATA_DIR + f\"train_images/{study_instance}/{dcm}\"\n            img = load_dicom(path)\n            \n            # resize each image into a shape of (512, 512)\n            img = np.resize(img, (512, 512))\n            #  normalize image\n            img = img / 255.0\n            # convert from gray scale to rgb, this will be helpful incase we want to use pretrained models\n            img = tf.expand_dims(img, axis=-1)\n            img = tf.image.grayscale_to_rgb(img)\n            \n            train_labels.extend([\n                train_df.loc[i, \"C1\"],\n                train_df.loc[i, \"C2\"],\n                train_df.loc[i, \"C3\"],\n                train_df.loc[i, \"C4\"],\n                train_df.loc[i, \"C5\"],\n                train_df.loc[i, \"C6\"],\n                train_df.loc[i, \"C7\"],\n                train_df.loc[i, \"patient_overall\"] # end with patient overall\n            ])\n            yield img, train_labels","metadata":{"execution":{"iopub.status.busy":"2022-09-03T12:15:15.155185Z","iopub.execute_input":"2022-09-03T12:15:15.155717Z","iopub.status.idle":"2022-09-03T12:15:15.172228Z","shell.execute_reply.started":"2022-09-03T12:15:15.155674Z","shell.execute_reply":"2022-09-03T12:15:15.171012Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# creating train, validation and test split for evaluation\ndef splitDataset(dataset, trainFactor, img_count): # here it refers to tf.dataset\n    train_dataset = dataset.take(int(trainFactor * img_count))\n    \n    valid_test_split = (1 - trainFactor) / 2\n    validation_dataset = dataset.take(int(valid_test_split* img_count))\n    test_dataset = dataset.take(int(valid_test_split* img_count))\n    return train_dataset, validation_dataset, test_dataset","metadata":{"execution":{"iopub.status.busy":"2022-09-03T12:17:24.528790Z","iopub.execute_input":"2022-09-03T12:17:24.529428Z","iopub.status.idle":"2022-09-03T12:17:24.536276Z","shell.execute_reply.started":"2022-09-03T12:17:24.529392Z","shell.execute_reply":"2022-09-03T12:17:24.534327Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def configure_for_performance(data):\n    data = data.cache()\n    data = data.batch(16)\n    data = data.prefetch(buffer_size=tf.data.AUTOTUNE)\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-09-03T12:15:21.447787Z","iopub.execute_input":"2022-09-03T12:15:21.448823Z","iopub.status.idle":"2022-09-03T12:15:21.454455Z","shell.execute_reply.started":"2022-09-03T12:15:21.448776Z","shell.execute_reply":"2022-09-03T12:15:21.453433Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def creating_model(hp):\n    IMG_SHAPE = (512, 512, 3)\n    base_model = tf.keras.applications.EfficientNetB5(input_shape=IMG_SHAPE,\n                                               include_top=False,\n                                               weights='imagenet')\n    \n    base_model.trainable = False\n    inputs = tf.keras.Input(shape=IMG_SHAPE)\n    x = base_model(inputs)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dropout(0.2)(x)\n    outputs = tf.keras.layers.Dense(8, activation = 'sigmoid')(x)\n    model = tf.keras.Model(inputs, outputs)\n    \n    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate), \n              loss=tf.keras.losses.BinaryCrossentropy(),\n              metrics=[tf.keras.metrics.BinaryAccuracy()])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-09-03T12:15:24.407275Z","iopub.execute_input":"2022-09-03T12:15:24.407885Z","iopub.status.idle":"2022-09-03T12:15:24.416460Z","shell.execute_reply.started":"2022-09-03T12:15:24.407835Z","shell.execute_reply":"2022-09-03T12:15:24.415300Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# this is required because of length of dataset is not valid for generators\ndef getImageCount():\n    img_count = 0\n    for _, study_instance in enumerate(train_df.StudyInstanceUID[:5]):\n        for _ in os.listdir(DATA_DIR + f\"train_images/{study_instance}\"):\n            img_count += 1\n            \n    return img_count","metadata":{"execution":{"iopub.status.busy":"2022-09-03T12:15:25.943500Z","iopub.execute_input":"2022-09-03T12:15:25.943856Z","iopub.status.idle":"2022-09-03T12:15:25.949652Z","shell.execute_reply.started":"2022-09-03T12:15:25.943820Z","shell.execute_reply":"2022-09-03T12:15:25.948324Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def createTensorboardCallback(logdir):\n    return tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1)\n\ndef saveModelCallback(filePath):\n    checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=filePath, monitor='val_loss',verbose=1, save_best_only=True, mode='min')\n    \n    return checkpoint","metadata":{"execution":{"iopub.status.busy":"2022-09-03T12:15:28.832528Z","iopub.execute_input":"2022-09-03T12:15:28.833036Z","iopub.status.idle":"2022-09-03T12:15:28.839524Z","shell.execute_reply.started":"2022-09-03T12:15:28.833001Z","shell.execute_reply":"2022-09-03T12:15:28.838486Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def display(history):\n    plt.plot(history.history['binary_accuracy'])\n    plt.plot(history.history['val_binary_accuracy'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n    # summarize history for loss\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-03T12:15:30.807312Z","iopub.execute_input":"2022-09-03T12:15:30.807679Z","iopub.status.idle":"2022-09-03T12:15:30.815614Z","shell.execute_reply.started":"2022-09-03T12:15:30.807644Z","shell.execute_reply":"2022-09-03T12:15:30.814427Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# getting the dataset\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n# creating the dataset\ndataset = tf.data.Dataset.from_generator(data_generator, (tf.float32, tf.int8))\n\n# printing a sample data for checking\nfor img, label in dataset.take(1):\n    print(img.shape)\n    print(label.shape)\n    print(label)\n\n# splitting the dataset\ntrainFactor = 0.8\nimg_count = getImageCount()\nprint(\"[***] Images for training and validation : \", img_count)\ntrain_data, validation_data, test_dataset = splitDataset(dataset, trainFactor, img_count)\n#\ntrain_dataset = configure_for_performance(train_data)\nvalidation_dataset = configure_for_performance(validation_data)\n\n# printing dataset structure after batching\nprint(\"[*] Dataset after batching\")\nfor img, label in train_dataset.take(1):\n    print(img.shape)\n    print(label.shape)","metadata":{"execution":{"iopub.status.busy":"2022-09-03T12:17:31.932797Z","iopub.execute_input":"2022-09-03T12:17:31.933820Z","iopub.status.idle":"2022-09-03T12:17:32.897768Z","shell.execute_reply.started":"2022-09-03T12:17:31.933774Z","shell.execute_reply":"2022-09-03T12:17:32.896684Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"(512, 512, 3)\n(8,)\ntf.Tensor([1 1 0 0 0 0 0 1], shape=(8,), dtype=int8)\n[***] Images for training and validation :  1734\n[*] Dataset after batching\n(16, 512, 512, 3)\n(16, 8)\n","output_type":"stream"},{"name":"stderr","text":"2022-09-03 12:17:32.886174: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Using Keras tuner to tune the learning rate and see improvements ##","metadata":{}},{"cell_type":"code","source":"mydir = \"/kaggle/working/my_dir\"\nos.makedirs(mydir, exist_ok=True)\n\ntuner = kt.Hyperband(creating_model,\n                     objective='val_binary_accuracy',\n                     max_epochs=50,\n                     factor=3,\n                     directory=mydir,\n                     project_name='rsna_baseline_improve_1')\n\n# creating a stop early callback\nstop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n\ntuner.search(train_dataset, epochs=10, validation_data = validation_dataset, callbacks=[stop_early])\n\n# Get the optimal hyperparameters\nbest_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n\nprint(f\"\"\"\nThe hyperparameter search is complete. The optimal learning rate for the optimizer\nis {best_hps.get('learning_rate')}\"\"\")\n\nprint(\"[*] Results Summary\")\nprint(tuner.results_summary())","metadata":{"execution":{"iopub.status.busy":"2022-09-03T12:18:34.634963Z","iopub.execute_input":"2022-09-03T12:18:34.635589Z","iopub.status.idle":"2022-09-03T12:18:40.121608Z","shell.execute_reply.started":"2022-09-03T12:18:34.635552Z","shell.execute_reply":"2022-09-03T12:18:40.120562Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"\nThe hyperparameter search is complete. The optimal learning rate for the optimizer\nis 0.0001\n[*] Results Summary\nResults summary\nResults in /kaggle/working/my_dir/rsna_baseline_improve_1\nShowing 10 best trials\n<keras_tuner.engine.objective.Objective object at 0x7fdb1ef25a10>\nTrial summary\nHyperparameters:\nlearning_rate: 0.0001\ntuner/epochs: 2\ntuner/initial_epoch: 0\ntuner/bracket: 3\ntuner/round: 0\nScore: 0.912211000919342\nTrial summary\nHyperparameters:\nlearning_rate: 0.01\ntuner/epochs: 2\ntuner/initial_epoch: 0\ntuner/bracket: 3\ntuner/round: 0\nScore: 0.662211000919342\nTrial summary\nHyperparameters:\nlearning_rate: 0.001\ntuner/epochs: 2\ntuner/initial_epoch: 0\ntuner/bracket: 3\ntuner/round: 0\nScore: 0.662211000919342\nNone\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Now training the model with the obtained tuned hyperparameters ##","metadata":{}},{"cell_type":"code","source":"# creating the model with the best hyperparameters\nmodel = tuner.hypermodel.build(best_hps)\nprint(model.summary)\nprint(model.optimizer.get_config())\n\n# training\nEPOCHS = 10\nBATCH_SIZE = 4\n# tensorboard logging dir\nfoldername = \"/kaggle/working/tensorboardRecord\"\nos.makedirs(foldername, exist_ok=True)\nlogdir = os.path.join(foldername, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\n\n# modelsave checkpoint\nmodelDir = \"/kaggle/working/modelDir\"\nos.makedirs(modelDir, exist_ok=True)\n#filepath = 'my_best_model.epoch{epoch:02d}-loss{val_loss:.2f}.hdf5'\nfilepath = 'best_model.hdf5'\nmodelSavePath = os.path.join(modelDir, filepath)\n\ntensorboardCallback = createTensorboardCallback(logdir)\nmodeSaveCallback = saveModelCallback(modelSavePath)\nhistory = model.fit(train_dataset, epochs = EPOCHS, validation_data = validation_dataset, callbacks=[modeSaveCallback])\n","metadata":{"execution":{"iopub.status.busy":"2022-09-03T12:44:54.807655Z","iopub.execute_input":"2022-09-03T12:44:54.808052Z","iopub.status.idle":"2022-09-03T12:52:13.909356Z","shell.execute_reply.started":"2022-09-03T12:44:54.808019Z","shell.execute_reply":"2022-09-03T12:52:13.908349Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"<bound method Model.summary of <keras.engine.functional.Functional object at 0x7fdb1c039b90>>\n{'name': 'Adam', 'learning_rate': 0.0001, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n","output_type":"stream"},{"name":"stderr","text":"2022-09-03 12:45:00.256100: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n2022-09-03 12:45:00.256139: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n2022-09-03 12:45:00.256258: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1614] Profiler found 1 GPUs\n2022-09-03 12:45:00.424755: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n2022-09-03 12:45:00.424970: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"2022-09-03 12:45:13.180301: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"87/87 [==============================] - 81s 776ms/step - loss: 0.4997 - binary_accuracy: 0.8344 - val_loss: 0.3778 - val_binary_accuracy: 0.8750\n\nEpoch 00001: val_loss improved from inf to 0.37783, saving model to /kaggle/working/modelDir/best_model.hdf5\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n  category=CustomMaskWarning)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/10\n87/87 [==============================] - 31s 360ms/step - loss: 0.2995 - binary_accuracy: 0.9145 - val_loss: 0.3480 - val_binary_accuracy: 0.8750\n\nEpoch 00002: val_loss improved from 0.37783 to 0.34798, saving model to /kaggle/working/modelDir/best_model.hdf5\nEpoch 3/10\n87/87 [==============================] - 31s 359ms/step - loss: 0.2566 - binary_accuracy: 0.9145 - val_loss: 0.3443 - val_binary_accuracy: 0.8750\n\nEpoch 00003: val_loss improved from 0.34798 to 0.34431, saving model to /kaggle/working/modelDir/best_model.hdf5\nEpoch 4/10\n87/87 [==============================] - 31s 358ms/step - loss: 0.2398 - binary_accuracy: 0.9145 - val_loss: 0.3436 - val_binary_accuracy: 0.8750\n\nEpoch 00004: val_loss improved from 0.34431 to 0.34358, saving model to /kaggle/working/modelDir/best_model.hdf5\nEpoch 5/10\n87/87 [==============================] - 31s 358ms/step - loss: 0.2322 - binary_accuracy: 0.9145 - val_loss: 0.3436 - val_binary_accuracy: 0.8750\n\nEpoch 00005: val_loss improved from 0.34358 to 0.34358, saving model to /kaggle/working/modelDir/best_model.hdf5\nEpoch 6/10\n87/87 [==============================] - 31s 358ms/step - loss: 0.2282 - binary_accuracy: 0.9145 - val_loss: 0.3417 - val_binary_accuracy: 0.8750\n\nEpoch 00006: val_loss improved from 0.34358 to 0.34169, saving model to /kaggle/working/modelDir/best_model.hdf5\nEpoch 7/10\n87/87 [==============================] - 31s 358ms/step - loss: 0.2254 - binary_accuracy: 0.9145 - val_loss: 0.3407 - val_binary_accuracy: 0.8750\n\nEpoch 00007: val_loss improved from 0.34169 to 0.34073, saving model to /kaggle/working/modelDir/best_model.hdf5\nEpoch 8/10\n87/87 [==============================] - 31s 359ms/step - loss: 0.2233 - binary_accuracy: 0.9145 - val_loss: 0.3402 - val_binary_accuracy: 0.8750\n\nEpoch 00008: val_loss improved from 0.34073 to 0.34021, saving model to /kaggle/working/modelDir/best_model.hdf5\nEpoch 9/10\n87/87 [==============================] - 31s 358ms/step - loss: 0.2221 - binary_accuracy: 0.9145 - val_loss: 0.3391 - val_binary_accuracy: 0.8750\n\nEpoch 00009: val_loss improved from 0.34021 to 0.33907, saving model to /kaggle/working/modelDir/best_model.hdf5\nEpoch 10/10\n87/87 [==============================] - 31s 359ms/step - loss: 0.2206 - binary_accuracy: 0.9145 - val_loss: 0.3385 - val_binary_accuracy: 0.8750\n\nEpoch 00010: val_loss improved from 0.33907 to 0.33851, saving model to /kaggle/working/modelDir/best_model.hdf5\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ndisplay(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}