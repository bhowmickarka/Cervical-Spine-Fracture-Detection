{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfrom glob import glob\nimport pydicom\nimport tensorflow as tf\nimport tqdm as tqdm\nimport tensorflow_io as tfio\n\"\"\"\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\"\"\"\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":5.477112,"end_time":"2022-08-01T23:24:50.070980","exception":false,"start_time":"2022-08-01T23:24:44.593868","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-12T15:36:11.864756Z","iopub.execute_input":"2022-08-12T15:36:11.865524Z","iopub.status.idle":"2022-08-12T15:36:19.070070Z","shell.execute_reply.started":"2022-08-12T15:36:11.865430Z","shell.execute_reply":"2022-08-12T15:36:19.068906Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"\"\\nfor dirname, _, filenames in os.walk('/kaggle/input'):\\n    for filename in filenames:\\n        print(os.path.join(dirname, filename))\\n\""},"metadata":{}}]},{"cell_type":"markdown","source":"# Creating the Dataset #","metadata":{"papermill":{"duration":0.003234,"end_time":"2022-08-01T23:24:50.076828","exception":false,"start_time":"2022-08-01T23:24:50.073594","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class cl_CreatingDataset:\n    def __init__(self, imageHeight, imageWidth, batch_size):\n        self.imageHeight = imageHeight\n        self.imageWidth = imageWidth\n        self.batch_size = batch_size\n\n    \n    def creatingPathList(self, trainImagesPath, trainDfPath):\n        trainDf = pd.read_csv(trainDfPath)\n        trainImagesPathList = []\n        labels = []\n        # reading the tain CSV\n        trainDf = pd.read_csv(trainDfPath)\n        for i in tqdm.tqdm(range(len(trainDf))):\n            folderName = trainDf[\"StudyInstanceUID\"].iloc[i]\n            imageFolderPath = os.path.join(trainImagesPath, folderName)\n\n            for file in glob(os.path.join(imageFolderPath, \"*.dcm\")):\n                # taking the imageName\n                trainImagesPathList.append(file)\n                # creating the labels\n                label = np.array([trainDf[\"C1\"].iloc[i],trainDf[\"C2\"].iloc[i], trainDf[\"C3\"].iloc[i], trainDf[\"C4\"].iloc[i], trainDf[\"C5\"].iloc[i], \n                                 trainDf[\"C6\"].iloc[i], trainDf[\"C7\"].iloc[i], trainDf[\"patient_overall\"].iloc[i]])\n                labels.append(label)\n        \n        return trainImagesPathList, labels\n    \n    \n    def parse_function(self, filename, label):\n        image_bytes = tf.io.read_file(filename)\n        image = tfio.image.decode_dicom_image(image_bytes, dtype=tf.float32)\n        #image = tf.image.convert_image_dtype(image, tf.float32)\n        resized_image = tf.image.resize(image, [self.imageHeight, self.imageWidth])\n        compressedImage = tf.squeeze(resized_image, axis = 0)\n        finalImage = tf.repeat(compressedImage, repeats=[3], axis = 2)\n        return finalImage, label\n        \n    def train_preprocess(self, image, label):\n        return image, label\n\n\n    def creatingDataset(self, filenames, labels):\n        dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n        dataset = dataset.shuffle(len(filenames))\n        dataset = dataset.map(self.parse_function, num_parallel_calls=4)\n        dataset = dataset.map(self.train_preprocess, num_parallel_calls=4)\n        dataset = dataset.batch(self.batch_size)\n        dataset = dataset.prefetch(1)\n\n        return dataset","metadata":{"papermill":{"duration":0.01753,"end_time":"2022-08-01T23:24:50.096873","exception":false,"start_time":"2022-08-01T23:24:50.079343","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-06T10:52:00.558602Z","iopub.execute_input":"2022-08-06T10:52:00.558988Z","iopub.status.idle":"2022-08-06T10:52:00.575730Z","shell.execute_reply.started":"2022-08-06T10:52:00.558957Z","shell.execute_reply":"2022-08-06T10:52:00.574549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Splitting the dataset ##","metadata":{}},{"cell_type":"code","source":"def splitDataset(dataset, trainFactor): # here it refers to tf.dataset\n    train_dataset = dataset.take(int(trainFactor * len(dataset)))\n    validation_dataset = dataset.take(int((1 - trainFactor)* len(dataset)))\n    \n    return train_dataset, validation_dataset\n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating the model ##","metadata":{}},{"cell_type":"code","source":"def creating_model():\n    IMG_SHAPE = (224, 224, 3)\n    base_model = tf.keras.applications.EfficientNetB5(input_shape=IMG_SHAPE,\n                                               include_top=False,\n                                               weights='imagenet')\n    \n    inputs = tf.keras.Input(shape=IMG_SHAPE)\n    x = base_model(x, training=False)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dropout(0.2)(x)\n    outputs = tf.keras.layers.Dense(8, activation = 'sigmoid')(x)\n    model = tf.keras.Model(inputs, outputs)\n    \n    return model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = creating_model()\n# compiling the model\nINIT_LR = 1e-3\nopt = Adam(lr=INIT_LR)\nmodel.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainCsv = \"../input/rsna-2022-cervical-spine-fracture-detection/train.csv\"\ntrainImagePath = \"../input/rsna-2022-cervical-spine-fracture-detection/train_images\"\ncreDataset = cl_CreatingDataset(64, 64, 4)\ntrainImagesPathList, labels = creDataset.creatingPathList(trainImagePath, trainCsv)\nprint(\"train Image list :\", len(trainImagePath), \".....\", \"train label list : \", len(labels))","metadata":{"execution":{"iopub.status.busy":"2022-08-06T10:52:02.201812Z","iopub.execute_input":"2022-08-06T10:52:02.202964Z","iopub.status.idle":"2022-08-06T10:53:06.879531Z","shell.execute_reply.started":"2022-08-06T10:52:02.202908Z","shell.execute_reply":"2022-08-06T10:53:06.877906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = creDataset.creatingDataset(trainImagesPathList, labels)","metadata":{"execution":{"iopub.status.busy":"2022-08-06T10:53:36.964138Z","iopub.execute_input":"2022-08-06T10:53:36.965046Z","iopub.status.idle":"2022-08-06T10:53:57.207475Z","shell.execute_reply.started":"2022-08-06T10:53:36.965002Z","shell.execute_reply":"2022-08-06T10:53:57.206525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for image, label in dataset.take(1):\n    imageNp = image.numpy()\n    print(imageNp.shape)","metadata":{"execution":{"iopub.status.busy":"2022-08-06T10:54:00.815652Z","iopub.execute_input":"2022-08-06T10:54:00.816254Z","iopub.status.idle":"2022-08-06T10:54:01.768640Z","shell.execute_reply.started":"2022-08-06T10:54:00.816220Z","shell.execute_reply":"2022-08-06T10:54:01.767419Z"},"trusted":true},"execution_count":null,"outputs":[]}]}