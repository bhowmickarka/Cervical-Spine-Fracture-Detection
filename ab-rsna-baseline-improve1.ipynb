{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q ../input/for-pydicom/pylibjpeg-1.4.0-py3-none-any.whl\n!pip install -q ../input/for-pydicom/python_gdcm-3.0.14-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n!pip install -q ../input/for-pydicom/pylibjpeg_libjpeg-1.3.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n!pip install -q -U keras-tuner","metadata":{"execution":{"iopub.status.busy":"2022-09-09T18:02:13.742655Z","iopub.execute_input":"2022-09-09T18:02:13.743357Z","iopub.status.idle":"2022-09-09T18:02:56.677276Z","shell.execute_reply.started":"2022-09-09T18:02:13.743249Z","shell.execute_reply":"2022-09-09T18:02:56.676109Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# Note : #\n\n### In this notebook we are going to use Keras tuner to tune hyperparamteres, like Learning Rate to see improvement in the training process ###","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfrom glob import glob\nimport pydicom\nimport tensorflow as tf\nimport tqdm as tqdm\nimport tensorflow_io as tfio\nimport pathlib\nimport datetime\nfrom tensorflow import keras\nimport keras_tuner as kt","metadata":{"execution":{"iopub.status.busy":"2022-09-09T18:03:29.868411Z","iopub.execute_input":"2022-09-09T18:03:29.868794Z","iopub.status.idle":"2022-09-09T18:03:36.457094Z","shell.execute_reply.started":"2022-09-09T18:03:29.868759Z","shell.execute_reply":"2022-09-09T18:03:36.456100Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"DATA_DIR = \"../input/rsna-2022-cervical-spine-fracture-detection/\"\ntrainCsv = \"../input/rsna-2022-cervical-spine-fracture-detection/train.csv\"\ntrain_df = pd.read_csv(trainCsv)\nprint(train_df.head())","metadata":{"execution":{"iopub.status.busy":"2022-09-09T18:03:41.649569Z","iopub.execute_input":"2022-09-09T18:03:41.650482Z","iopub.status.idle":"2022-09-09T18:03:41.680069Z","shell.execute_reply.started":"2022-09-09T18:03:41.650448Z","shell.execute_reply":"2022-09-09T18:03:41.678598Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"            StudyInstanceUID  patient_overall  C1  C2  C3  C4  C5  C6  C7\n0   1.2.826.0.1.3680043.6200                1   1   1   0   0   0   0   0\n1  1.2.826.0.1.3680043.27262                1   0   1   0   0   0   0   0\n2  1.2.826.0.1.3680043.21561                1   0   1   0   0   0   0   0\n3  1.2.826.0.1.3680043.12351                0   0   0   0   0   0   0   0\n4   1.2.826.0.1.3680043.1363                1   0   0   0   0   1   0   0\n","output_type":"stream"}]},{"cell_type":"code","source":"def load_dicom(path):\n    \"\"\"\n    reads a dicom file and loads the image array inside it\n    inputs:\n        path: the path of the required dicom file\n    returns:\n        data: image pixel arrays\n    \"\"\"\n    img=pydicom.dcmread(path)\n    data=img.pixel_array\n    data=data-np.min(data)\n    if np.max(data) != 0:\n        data=data/np.max(data)\n    data=(data*255).astype(np.uint8)\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-09-09T18:03:43.766890Z","iopub.execute_input":"2022-09-09T18:03:43.767289Z","iopub.status.idle":"2022-09-09T18:03:43.773756Z","shell.execute_reply.started":"2022-09-09T18:03:43.767257Z","shell.execute_reply":"2022-09-09T18:03:43.772702Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def data_generator():\n    for i, study_instance in enumerate(train_df.StudyInstanceUID[:]):\n        for dcm in os.listdir(DATA_DIR + f\"train_images/{study_instance}\"):\n            train_labels = []\n            path = DATA_DIR + f\"train_images/{study_instance}/{dcm}\"\n            img = load_dicom(path)\n            \n            # resize each image into a shape of (512, 512)\n            img = np.resize(img, (128, 128))\n            #  normalize image\n            img = img / 255.0\n            # convert from gray scale to rgb, this will be helpful incase we want to use pretrained models\n            img = tf.expand_dims(img, axis=-1)\n            img = tf.image.grayscale_to_rgb(img)\n            \n            train_labels.extend([\n                train_df.loc[i, \"C1\"],\n                train_df.loc[i, \"C2\"],\n                train_df.loc[i, \"C3\"],\n                train_df.loc[i, \"C4\"],\n                train_df.loc[i, \"C5\"],\n                train_df.loc[i, \"C6\"],\n                train_df.loc[i, \"C7\"],\n                train_df.loc[i, \"patient_overall\"] # end with patient overall\n            ])\n            yield img, train_labels","metadata":{"execution":{"iopub.status.busy":"2022-09-09T18:03:45.087090Z","iopub.execute_input":"2022-09-09T18:03:45.087785Z","iopub.status.idle":"2022-09-09T18:03:45.096087Z","shell.execute_reply.started":"2022-09-09T18:03:45.087750Z","shell.execute_reply":"2022-09-09T18:03:45.094934Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# creating train, validation and test split for evaluation\ndef splitDataset(dataset, trainFactor, img_count): # here it refers to tf.dataset\n    train_dataset = dataset.take(int(trainFactor * img_count))\n    \n    valid_test_split = (1 - trainFactor) / 2\n    validation_dataset = dataset.take(int(valid_test_split* img_count))\n    test_dataset = dataset.take(int(valid_test_split* img_count))\n    return train_dataset, validation_dataset, test_dataset","metadata":{"execution":{"iopub.status.busy":"2022-09-09T18:03:49.782440Z","iopub.execute_input":"2022-09-09T18:03:49.782911Z","iopub.status.idle":"2022-09-09T18:03:49.790251Z","shell.execute_reply.started":"2022-09-09T18:03:49.782873Z","shell.execute_reply":"2022-09-09T18:03:49.789014Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def configure_for_performance(data):\n    data = data.cache()\n    data = data.batch(16)\n    data = data.prefetch(buffer_size=tf.data.AUTOTUNE)\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-09-09T18:03:53.074920Z","iopub.execute_input":"2022-09-09T18:03:53.075396Z","iopub.status.idle":"2022-09-09T18:03:53.081314Z","shell.execute_reply.started":"2022-09-09T18:03:53.075360Z","shell.execute_reply":"2022-09-09T18:03:53.080439Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def creating_model(hp):\n    IMG_SHAPE = (128, 128, 3)\n    base_model = tf.keras.applications.EfficientNetB5(input_shape=IMG_SHAPE,\n                                               include_top=False,\n                                               weights='imagenet')\n    \n    base_model.trainable = False\n    inputs = tf.keras.Input(shape=IMG_SHAPE)\n    x = base_model(inputs)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dropout(0.2)(x)\n    outputs = tf.keras.layers.Dense(8, activation = 'sigmoid')(x)\n    model = tf.keras.Model(inputs, outputs)\n    \n    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate), \n              loss=tf.keras.losses.BinaryCrossentropy(),\n              metrics=[tf.keras.metrics.BinaryAccuracy()])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-09-09T18:04:02.941640Z","iopub.execute_input":"2022-09-09T18:04:02.941999Z","iopub.status.idle":"2022-09-09T18:04:02.949937Z","shell.execute_reply.started":"2022-09-09T18:04:02.941969Z","shell.execute_reply":"2022-09-09T18:04:02.948944Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# this is required because of length of dataset is not valid for generators\ndef getImageCount():\n    img_count = 0\n    for _, study_instance in enumerate(train_df.StudyInstanceUID[:5]):\n        for _ in os.listdir(DATA_DIR + f\"train_images/{study_instance}\"):\n            img_count += 1\n            \n    return img_count","metadata":{"execution":{"iopub.status.busy":"2022-09-09T18:04:05.626446Z","iopub.execute_input":"2022-09-09T18:04:05.626809Z","iopub.status.idle":"2022-09-09T18:04:05.632457Z","shell.execute_reply.started":"2022-09-09T18:04:05.626779Z","shell.execute_reply":"2022-09-09T18:04:05.631357Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def createTensorboardCallback(logdir):\n    return tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1)\n\ndef saveModelCallback(filePath):\n    checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=filePath, monitor='val_loss',verbose=1, save_best_only=True, mode='min')\n    \n    return checkpoint","metadata":{"execution":{"iopub.status.busy":"2022-09-09T18:04:07.105933Z","iopub.execute_input":"2022-09-09T18:04:07.106840Z","iopub.status.idle":"2022-09-09T18:04:07.112391Z","shell.execute_reply.started":"2022-09-09T18:04:07.106802Z","shell.execute_reply":"2022-09-09T18:04:07.111236Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def display(history):\n    plt.plot(history.history['binary_accuracy'])\n    plt.plot(history.history['val_binary_accuracy'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n    # summarize history for loss\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-09T18:04:08.623369Z","iopub.execute_input":"2022-09-09T18:04:08.623843Z","iopub.status.idle":"2022-09-09T18:04:08.637547Z","shell.execute_reply.started":"2022-09-09T18:04:08.623802Z","shell.execute_reply":"2022-09-09T18:04:08.636285Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# getting the dataset\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n# creating the dataset\ndataset = tf.data.Dataset.from_generator(data_generator, (tf.float32, tf.int8))\n\n# printing a sample data for checking\nfor img, label in dataset.take(1):\n    print(img.shape)\n    print(label.shape)\n    print(label)\n\n# splitting the dataset\ntrainFactor = 0.8\nimg_count = getImageCount()\nprint(\"[***] Images for training and validation : \", img_count)\ntrain_data, validation_data, test_dataset = splitDataset(dataset, trainFactor, img_count)\n#\ntrain_dataset = configure_for_performance(train_data)\nvalidation_dataset = configure_for_performance(validation_data)\n\n# printing dataset structure after batching\nprint(\"[*] Dataset after batching\")\nfor img, label in train_dataset.take(1):\n    print(img.shape)\n    print(label.shape)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T18:04:10.998207Z","iopub.execute_input":"2022-09-09T18:04:10.998566Z","iopub.status.idle":"2022-09-09T18:04:15.325280Z","shell.execute_reply.started":"2022-09-09T18:04:10.998538Z","shell.execute_reply":"2022-09-09T18:04:15.324221Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"2022-09-09 18:04:11.079110: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-09 18:04:11.247534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-09 18:04:11.248575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-09 18:04:11.251785: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-09-09 18:04:11.252120: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-09 18:04:11.252829: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-09 18:04:11.253475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-09 18:04:13.743341: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-09 18:04:13.744219: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-09 18:04:13.744888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-09 18:04:13.745527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n2022-09-09 18:04:14.185208: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"(128, 128, 3)\n(8,)\ntf.Tensor([1 1 0 0 0 0 0 1], shape=(8,), dtype=int8)\n[***] Images for training and validation :  1734\n[*] Dataset after batching\n(16, 128, 128, 3)\n(16, 8)\n","output_type":"stream"},{"name":"stderr","text":"2022-09-09 18:04:15.316330: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Using Keras tuner to tune the learning rate and see improvements ##","metadata":{}},{"cell_type":"code","source":"mydir = \"/kaggle/working/my_dir\"\nos.makedirs(mydir, exist_ok=True)\n\ntuner = kt.Hyperband(creating_model,\n                     objective='val_binary_accuracy',\n                     max_epochs=50,\n                     factor=3,\n                     directory=mydir,\n                     project_name='rsna_baseline_improve_1')\n\n# creating a stop early callback\nstop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n\ntuner.search(train_dataset, epochs=10, validation_data = validation_dataset, callbacks=[stop_early])\n\n# Get the optimal hyperparameters\nbest_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n\nprint(f\"\"\"\nThe hyperparameter search is complete. The optimal learning rate for the optimizer\nis {best_hps.get('learning_rate')}\"\"\")\n\nprint(\"[*] Results Summary\")\nprint(tuner.results_summary())","metadata":{"execution":{"iopub.status.busy":"2022-09-09T18:04:20.176910Z","iopub.execute_input":"2022-09-09T18:04:20.177517Z","iopub.status.idle":"2022-09-09T18:07:13.101825Z","shell.execute_reply.started":"2022-09-09T18:04:20.177482Z","shell.execute_reply":"2022-09-09T18:07:13.100727Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Trial 3 Complete [00h 00m 32s]\nval_binary_accuracy: 0.625\n\nBest val_binary_accuracy So Far: 1.0\nTotal elapsed time: 00h 02m 46s\n\nThe hyperparameter search is complete. The optimal learning rate for the optimizer\nis 0.01\n[*] Results Summary\nResults summary\nResults in /kaggle/working/my_dir/rsna_baseline_improve_1\nShowing 10 best trials\n<keras_tuner.engine.objective.Objective object at 0x7fc26a2af3d0>\nTrial summary\nHyperparameters:\nlearning_rate: 0.01\ntuner/epochs: 2\ntuner/initial_epoch: 0\ntuner/bracket: 3\ntuner/round: 0\nScore: 1.0\nTrial summary\nHyperparameters:\nlearning_rate: 0.0001\ntuner/epochs: 2\ntuner/initial_epoch: 0\ntuner/bracket: 3\ntuner/round: 0\nScore: 0.875\nTrial summary\nHyperparameters:\nlearning_rate: 0.001\ntuner/epochs: 2\ntuner/initial_epoch: 0\ntuner/bracket: 3\ntuner/round: 0\nScore: 0.625\nNone\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Now training the model with the obtained tuned hyperparameters ##","metadata":{}},{"cell_type":"code","source":"# creating the model with the best hyperparameters\nmodel = tuner.hypermodel.build(best_hps)\nprint(model.summary)\nprint(model.optimizer.get_config())\n\n# training\nEPOCHS = 10\nBATCH_SIZE = 4\n# tensorboard logging dir\nfoldername = \"/kaggle/working/tensorboardRecord\"\nos.makedirs(foldername, exist_ok=True)\nlogdir = os.path.join(foldername, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\n\n# modelsave checkpoint\nmodelDir = \"/kaggle/working/modelDir\"\nos.makedirs(modelDir, exist_ok=True)\n#filepath = 'my_best_model.epoch{epoch:02d}-loss{val_loss:.2f}.hdf5'\nfilepath = 'best_model.hdf5'\nmodelSavePath = os.path.join(modelDir, filepath)\n\ntensorboardCallback = createTensorboardCallback(logdir)\nmodeSaveCallback = saveModelCallback(modelSavePath)\nhistory = model.fit(train_dataset, epochs = EPOCHS, validation_data = validation_dataset, callbacks=[modeSaveCallback])\n","metadata":{"execution":{"iopub.status.busy":"2022-09-09T18:08:03.679161Z","iopub.execute_input":"2022-09-09T18:08:03.680027Z","iopub.status.idle":"2022-09-09T18:09:12.306762Z","shell.execute_reply.started":"2022-09-09T18:08:03.679993Z","shell.execute_reply":"2022-09-09T18:09:12.305809Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"<bound method Model.summary of <keras.engine.functional.Functional object at 0x7fbd8d65c550>>\n{'name': 'Adam', 'learning_rate': 0.01, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n","output_type":"stream"},{"name":"stderr","text":"2022-09-09 18:08:08.693464: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n2022-09-09 18:08:08.693505: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n2022-09-09 18:08:08.694299: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1614] Profiler found 1 GPUs\n2022-09-09 18:08:09.037722: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n2022-09-09 18:08:09.037933: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n87/87 [==============================] - 21s 81ms/step - loss: 2.3623 - binary_accuracy: 0.8386 - val_loss: 1.9281 - val_binary_accuracy: 0.8750\n\nEpoch 00001: val_loss improved from inf to 1.92812, saving model to /kaggle/working/modelDir/best_model.hdf5\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n  category=CustomMaskWarning)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/10\n87/87 [==============================] - 4s 46ms/step - loss: 1.3081 - binary_accuracy: 0.9145 - val_loss: 1.9281 - val_binary_accuracy: 0.8750\n\nEpoch 00002: val_loss did not improve from 1.92812\nEpoch 3/10\n87/87 [==============================] - 4s 44ms/step - loss: 1.3081 - binary_accuracy: 0.9145 - val_loss: 1.9281 - val_binary_accuracy: 0.8750\n\nEpoch 00003: val_loss did not improve from 1.92812\nEpoch 4/10\n87/87 [==============================] - 4s 46ms/step - loss: 1.3081 - binary_accuracy: 0.9145 - val_loss: 1.9281 - val_binary_accuracy: 0.8750\n\nEpoch 00004: val_loss did not improve from 1.92812\nEpoch 5/10\n87/87 [==============================] - 4s 44ms/step - loss: 1.3081 - binary_accuracy: 0.9145 - val_loss: 1.9281 - val_binary_accuracy: 0.8750\n\nEpoch 00005: val_loss did not improve from 1.92812\nEpoch 6/10\n87/87 [==============================] - 4s 49ms/step - loss: 1.3071 - binary_accuracy: 0.9145 - val_loss: 1.9281 - val_binary_accuracy: 0.8750\n\nEpoch 00006: val_loss did not improve from 1.92812\nEpoch 7/10\n87/87 [==============================] - 4s 43ms/step - loss: 0.8661 - binary_accuracy: 0.9411 - val_loss: 5.7844 - val_binary_accuracy: 0.6250\n\nEpoch 00007: val_loss did not improve from 1.92812\nEpoch 8/10\n87/87 [==============================] - 4s 44ms/step - loss: 3.2126 - binary_accuracy: 0.7917 - val_loss: 5.7844 - val_binary_accuracy: 0.6250\n\nEpoch 00008: val_loss did not improve from 1.92812\nEpoch 9/10\n87/87 [==============================] - 4s 45ms/step - loss: 3.2126 - binary_accuracy: 0.7917 - val_loss: 5.7844 - val_binary_accuracy: 0.6250\n\nEpoch 00009: val_loss did not improve from 1.92812\nEpoch 10/10\n87/87 [==============================] - 4s 44ms/step - loss: 3.2126 - binary_accuracy: 0.7917 - val_loss: 5.7844 - val_binary_accuracy: 0.6250\n\nEpoch 00010: val_loss did not improve from 1.92812\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ndisplay(history)","metadata":{"execution":{"iopub.status.busy":"2022-09-05T22:32:35.541058Z","iopub.execute_input":"2022-09-05T22:32:35.542133Z","iopub.status.idle":"2022-09-05T22:32:35.950063Z","shell.execute_reply.started":"2022-09-05T22:32:35.542093Z","shell.execute_reply":"2022-09-05T22:32:35.949044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"./modelDir","metadata":{},"execution_count":null,"outputs":[]}]}